{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# CSE 253: Programming Assignment 1\n",
    "# Code snippet by Jenny Hamer\n",
    "# Winter 2019\n",
    "################################################################################\n",
    "# We've provided you with the dataset in CAFE.tar.gz. To uncompress, use:\n",
    "# tar -xzvf CAFE.tar.gz\n",
    "################################################################################\n",
    "# To install PIL, refer to the instructions for your system:\n",
    "# https://pillow.readthedocs.io/en/5.2.x/installation.html\n",
    "################################################################################\n",
    "# If you don't have NumPy installed, please use the instructions here:\n",
    "# https://scipy.org/install.html\n",
    "################################################################################\n",
    "\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# The relative path to your CAFE-Gamma dataset\n",
    "data_dir = \"./CAFE/\"\n",
    "\n",
    "# Dictionary of semantic \"label\" to emotions\n",
    "emotion_dict = {\"h\": \"happy\", \"ht\": \"happy with teeth\", \"m\": \"maudlin\",\n",
    "\t\"s\": \"surprise\", \"f\": \"fear\", \"a\": \"anger\", \"d\": \"disgust\", \"n\": \"neutral\"}\n",
    "\n",
    "\n",
    "def load_data(data_dir=\"./CAFE/\"):\n",
    "    \"\"\" Load all PGM images stored in your data directory into a list of NumPy\n",
    "    arrays with a list of corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        data_dir: The relative filepath to the CAFE dataset.\n",
    "    Returns:\n",
    "        images: A list containing every image in CAFE as an array.\n",
    "        labels: A list of the corresponding labels (filenames) for each image.\n",
    "    \"\"\"\n",
    "    # Get the list of image file names\n",
    "    all_files = listdir(data_dir)\n",
    "\n",
    "    # Store the images as arrays and their labels in two lists\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for file in all_files:\n",
    "    # Load in the files as PIL images and convert to NumPy arrays\n",
    "        if file.find('_ht') == -1 and file.find('_n') == -1:\n",
    "            img = Image.open(data_dir + file)\n",
    "            images.append(np.array(img))\n",
    "            labels.append(file)\n",
    "\n",
    "    print(\"Total number of images:\", len(images), \"and labels:\", len(labels))\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(data_ori, dims_rescaled_data=2):\n",
    "    \"\"\"\n",
    "    returns: data transformed in 2 dims/columns + regenerated original data\n",
    "    pass in: data as 2D NumPy array\n",
    "    \"\"\"\n",
    "    data = data_ori.transpose()\n",
    "    import numpy as NP\n",
    "    from scipy import linalg as LA\n",
    "    m, n = data.shape\n",
    "    # mean center the data\n",
    "    data -= data.mean(axis=0)\n",
    "    data /= data.std(axis=0)\n",
    "    # calculate the covariance matrix\n",
    "    R = NP.cov(data, rowvar=False)\n",
    "    # calculate eigenvectors & eigenvalues of the covariance matrix\n",
    "    # use 'eigh' rather than 'eig' since R is symmetric, \n",
    "    # the performance gain is substantial\n",
    "    evals, evecs = LA.eigh(R)\n",
    "    print(evals.shape)\n",
    "    print(evecs.shape)\n",
    "    # sort eigenvalue in decreasing order\n",
    "    idx = NP.argsort(evals)[::-1]\n",
    "    evecs = evecs[:,idx]\n",
    "    # sort eigenvectors according to same index\n",
    "    evals = evals[idx]\n",
    "    # select the first n eigenvectors (n is desired dimension\n",
    "    # of resca?led data array, or dims_rescaled_data)\n",
    "    evecs = evecs[:, :dims_rescaled_data]\n",
    "    vect = NP.dot(evecs.T, data.T).T\n",
    "    # carry out the transformation on the data using eigenvectors\n",
    "    # and return the re-scaled data, eigenvalues, and eigenvectors\n",
    "    print(data_ori.shape)\n",
    "    print(vect.shape)\n",
    "    print(NP.matmul(data_ori,vect).shape)\n",
    "    vect = vect - vect.mean(axis = 0)\n",
    "    vect = vect / vect.std(axis = 0)\n",
    "    result = NP.matmul(data.transpose(),vect)\n",
    "    result = np.transpose(result.T - result.mean(axis = 1).T)\n",
    "    result = np.transpose(result.T / result.std(axis = 1).T)\n",
    "    return result,vect\n",
    "\n",
    "def test_PCA(data, dims_rescaled_data=2):\n",
    "    '''\n",
    "    test by attempting to recover original data array from\n",
    "    the eigenvectors of its covariance matrix & comparing that\n",
    "    'recovered' array with the original data\n",
    "    '''\n",
    "    _ , _ , eigenvectors = PCA(data, dim_rescaled_data=2)\n",
    "    data_recovered = NP.dot(eigenvectors, m).T\n",
    "    data_recovered += data_recovered.mean(axis=0)\n",
    "    assert NP.allclose(data, data_recovered)\n",
    "\n",
    "\n",
    "def plot_pca(data):\n",
    "    from matplotlib import pyplot as MPL\n",
    "    clr1 =  '#2026B2'\n",
    "    fig = MPL.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    data_resc, data_orig = PCA(data)\n",
    "    ax1.plot(data_resc[:, 0], data_resc[:, 1], '.', mfc=clr1, mec=clr1)\n",
    "    MPL.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 60 and labels: 60\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "images, labels = load_data(data_dir=\"./CAFE/\")\n",
    "im = np.array(images[:48], 'float64')\n",
    "im_re = np.reshape(im, [len(im), -1])\n",
    "pca_result,evecs = PCA(im_re, dims_rescaled_data=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "evecs = evecs/evecs.std(axis=0)\n",
    "evecs = evecs-evecs.mean(axis=0)\n",
    "evecs_pic = np.reshape(np.transpose(evecs),[6,380,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_face(img):\n",
    "    \"\"\" Display the input image and optionally save as a PNG.\n",
    "\n",
    "    Args:\n",
    "    img: The NumPy array or image to display\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    # Convert img to PIL Image object (if it's an ndarray)\n",
    "    if type(img) == np.ndarray:\n",
    "        print(\"Converting from array to PIL Image\")\n",
    "        im = (img - img.min())*(255/(img.max()-img.min()))\n",
    "        # normalize the img into 0-255\n",
    "        img = Image.fromarray(im)\n",
    "    # Display the image\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting from array to PIL Image\n",
      "Converting from array to PIL Image\n",
      "Converting from array to PIL Image\n",
      "Converting from array to PIL Image\n",
      "Converting from array to PIL Image\n",
      "Converting from array to PIL Image\n"
     ]
    }
   ],
   "source": [
    "display_face(evecs_pic[0,:,:])\n",
    "display_face(evecs_pic[1,:,:])\n",
    "display_face(evecs_pic[2,:,:])\n",
    "display_face(evecs_pic[3,:,:])\n",
    "display_face(evecs_pic[4,:,:])\n",
    "display_face(evecs_pic[5,:,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_happy_sad(data_dir=\"./CAFE/\"):\n",
    "    \"\"\" Load all PGM images stored in your data directory into a list of NumPy\n",
    "    arrays with a list of corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        data_dir: The relative filepath to the CAFE dataset.\n",
    "    Returns:\n",
    "        images: A list containing every image in CAFE as an array.\n",
    "        labels: A list of the corresponding labels (filenames) for each image.\n",
    "    \"\"\"\n",
    "    # Get the list of image file names\n",
    "    all_files = listdir(data_dir)\n",
    "\n",
    "    # Store the images as arrays and their labels in two lists\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for file in all_files:\n",
    "    # Load in the files as PIL images and convert to NumPy arrays\n",
    "        if file.find('_h') != -1 or file.find('_m')!=-1 :\n",
    "            img = Image.open(data_dir + file)\n",
    "            images.append(np.array(img))\n",
    "            labels.append(file)\n",
    "\n",
    "    print(\"Total number of h_m:\", len(images), \"and labels:\", len(labels))\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sad(images, labels):\n",
    "    image_sad = []\n",
    "    for i in range(len(images)):\n",
    "        if labels[i].find('_m') != -1:\n",
    "            image_sad.append(images[i])\n",
    "    return image_sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sad_vector = get_sad(images, labels)\n",
    "sad =np.array(np.reshape(sad_vector,[len(sad_vector),-1]),'float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_happy(images, labels):\n",
    "    image_happy = []\n",
    "    for i in range(len(images)):\n",
    "        if labels[i].find('_h') != -1:\n",
    "            image_happy.append(images[i])\n",
    "    return image_happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 380, 240)\n"
     ]
    }
   ],
   "source": [
    "happy_vector = get_happy(images, labels)\n",
    "print(np.array(happy_vector).shape)\n",
    "happy=np.array(np.reshape(happy_vector,[len(happy_vector),-1]),'float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate((sad[:8],happy[:8]),axis=0)\n",
    "labels_1 = np.concatenate(([0]*8,[1]*8),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_feature = np.concatenate((sad[7:8],happy[7:8]),axis=0)\n",
    "holdout_label = np.concatenate(([0],[1]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature = np.concatenate((sad[8:9],happy[8:9]),axis=0)\n",
    "test_label = np.concatenate(([0],[1]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16,)\n",
      "(16, 16)\n",
      "(16, 91200)\n",
      "(91200, 15)\n",
      "(16, 15)\n"
     ]
    }
   ],
   "source": [
    "features_pca, evect = PCA(features, dims_rescaled_data=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.82948095,  2.85550848, -1.24678986,  0.47655301,  0.27357105,\n",
       "         0.08044501, -0.11779909,  0.4564379 , -0.61105113, -0.51454176,\n",
       "        -0.18231453, -0.35550254,  0.77393048, -0.11750038,  0.05853431],\n",
       "       [-2.82609533,  1.6084112 ,  0.9745908 , -1.11935066,  0.17168092,\n",
       "         0.81782256,  0.86950537, -0.44732322, -0.19798486,  0.20882141,\n",
       "        -0.01740262,  0.24904784,  0.26675438,  0.03440187, -0.59287965],\n",
       "       [-2.84629722,  0.80422512,  1.85801394, -0.38374653,  0.4927662 ,\n",
       "        -0.1153255 , -0.79465616, -0.12295929,  0.34716095, -0.61723477,\n",
       "         1.10577839,  0.03853081,  0.06268005,  0.03390454,  0.13715949],\n",
       "       [-3.11235849, -0.61736027,  0.39433414,  1.62178208, -0.48828385,\n",
       "        -0.09880345,  1.08101917, -0.32086095, -0.04867171,  0.0250695 ,\n",
       "         0.38000871,  0.18459528,  0.34509901,  0.56382093,  0.0906099 ],\n",
       "       [-2.4591408 ,  1.56250366, -0.69647371,  0.92347969, -1.14326777,\n",
       "         1.20201062, -0.83511168, -0.60710734,  0.93715093,  0.65400156,\n",
       "         0.14738457,  0.03627636,  0.09572527,  0.07396604,  0.1086026 ],\n",
       "       [-2.80426833, -0.74468785,  0.20760558, -0.4845742 , -1.23207409,\n",
       "         0.80212243, -0.01410228,  1.13933618, -0.48944587,  0.35277249,\n",
       "         0.55759749,  0.61381248,  0.36362713,  1.14863547,  0.58364338],\n",
       "       [-2.64171705,  1.74947012, -1.18729458, -0.44017658,  0.56554546,\n",
       "        -1.07123189,  0.17794622, -0.39574361,  0.47001392,  0.44324401,\n",
       "         0.2919996 ,  0.25802035,  0.40684826,  0.57655258,  0.79652319],\n",
       "       [-3.1802389 ,  0.81647448,  1.42255991,  0.40699737,  0.31795334,\n",
       "        -0.00888166, -0.34756601,  0.10642847,  0.16775458, -0.20320396,\n",
       "        -0.822984  ,  0.96998622,  0.00921443,  0.01552273,  0.32998302],\n",
       "       [-2.71700496, -1.06621886, -0.95061   , -0.7330781 ,  0.64150766,\n",
       "        -0.71631279,  0.64263199,  0.20306202,  1.20578024,  0.5948129 ,\n",
       "         0.49135553,  0.74570166,  0.83977704,  0.49780731,  0.32078835],\n",
       "       [-3.01682742, -1.18418274,  0.06120275,  0.17078883, -0.52140592,\n",
       "         0.4295801 ,  0.34773626,  1.47295203,  0.3486763 ,  0.54810375,\n",
       "         0.57493511,  0.48925106,  0.55564206, -0.57283897,  0.2963868 ],\n",
       "       [-1.94460978, -1.64969468, -1.09950896,  0.65099544,  1.9316691 ,\n",
       "         1.20287137, -0.30747017, -0.37597056, -0.6677501 ,  0.51073961,\n",
       "         0.51982551,  0.55849318,  0.20634336,  0.15782574,  0.30624095],\n",
       "       [-2.5298322 , -1.79232916, -0.21499804,  0.27286421,  0.9785938 ,\n",
       "         1.30326262,  0.2652994 ,  0.70160616,  1.17418459, -0.51501826,\n",
       "        -0.2133387 , -0.24253618,  0.21142914,  0.49350118,  0.10731144],\n",
       "       [-2.95994053, -0.10503705,  1.52600631,  0.58855758,  0.88293751,\n",
       "        -0.70484851, -0.6638928 ,  0.67145056, -0.04794362,  1.0142413 ,\n",
       "        -0.15251877, -0.43084015,  0.1817917 ,  0.31415566, -0.1141192 ],\n",
       "       [-3.03499649, -0.6496127 ,  0.62151172,  1.92633703, -0.04548107,\n",
       "        -0.37954797,  0.96463211, -0.14855835,  0.09490583,  0.02389789,\n",
       "         0.28356226,  0.08078228,  0.05100924, -0.05161626,  0.26317449],\n",
       "       [-3.19942622,  0.60579453,  0.74179277, -1.04099705,  0.33522803,\n",
       "         0.77245096,  1.08084114, -0.02283115,  0.05485849,  0.47057088,\n",
       "         0.03879265, -0.35747237, -0.16573598, -0.02323971,  0.70937301],\n",
       "       [-2.34717181,  2.25099292, -1.44667545,  0.37498   ,  0.52231735,\n",
       "        -0.2438555 ,  0.34910975,  0.8784712 ,  0.14546581,  0.0142901 ,\n",
       "         0.27226579,  0.22628657, -0.87064633,  0.09805821, -0.2238886 ]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def sigmoid(scores):\n",
    "    return 1 / (1 + np.exp(-scores))\n",
    "def loss(t, y):\n",
    "    return -(t * np.log(y) +(1 - t) * np.log(1 - y)).mean()\n",
    "def accuracy(t,p):\n",
    "    return 1-1.0*sum(abs(t-(p>0.5)))/len(t)\n",
    "def logistic_regression(features, target, num_steps, learning_rate, add_intercept = False):\n",
    "    ce_loss = []\n",
    "    if add_intercept:\n",
    "        intercept = np.ones((features.shape[0], 1))\n",
    "        features = np.hstack((intercept, features))   \n",
    "    weights = np.zeros(features.shape[1])\n",
    "    for step in range(num_steps):\n",
    "        scores = np.dot(features, weights)\n",
    "        predictions = sigmoid(scores)\n",
    "        # Update weights with gradient\n",
    "        gradient = np.dot(features.T, target-predictions)\n",
    "        weights += learning_rate * gradient\n",
    "        # Print log-likelihood every so often\n",
    "        ce_loss.append(loss(target,sigmoid(np.dot(features,weights))))\n",
    "    return weights,ce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_overall=[]\n",
    "for i in range(10):\n",
    "    [weight,ce_loss] = logistic_regression(features_pca, labels_1, 10, 0.1, add_intercept = False)\n",
    "    loss_overall.append(ce_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_pca = np.dot(holdout_feature,evect)\n",
    "holdout_pca = holdout_pca - holdout_pca.mean()\n",
    "holdout_pca = holdout_pca / holdout_pca.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.59456151,  0.82955879,  1.50045876,  0.37629237,  0.27772601,\n",
       "        -0.08406059, -0.45896371,  0.04358075,  0.11146505, -0.29916364,\n",
       "        -0.98522272,  0.99948702, -0.06402932, -0.05704641,  0.29104213],\n",
       "       [-1.97691541,  2.04132495, -1.1899904 ,  0.40191635,  0.53067138,\n",
       "        -0.13887111,  0.37930887,  0.84190681,  0.20134868,  0.08671695,\n",
       "         0.31215654,  0.27197625, -0.68661055,  0.15992016, -0.12142244]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_result = sigmoid(np.dot(holdout_pca,weight)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1421452 , 0.67520279])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
