{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from easydict import EasyDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from random import shuffle\n",
    "from data_handler import *\n",
    "import utils\n",
    "import itertools\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in our whole tunes database = 93\n",
      "CUDA is supported\n",
      "Model on CUDA? True\n"
     ]
    }
   ],
   "source": [
    "opts = EasyDict()\n",
    "opts.data_directory = \"./Data/\"\n",
    "opts.train_data_file = \"train.txt\"\n",
    "opts.val_data_file = \"val.txt\"\n",
    "opts.n_epochs = 100\n",
    "opts.batch_size = 1  # TODO minibatch size 1 for simplifying / taking chunks of 100\n",
    "opts.seq_length = 100\n",
    "opts.learning_rate = 0.01\n",
    "opts.lr_decay = 0.99\n",
    "opts.hidden_size = 100\n",
    "opts.generate_seq_length = 2000\n",
    "opts.temperature = 1.8\n",
    "opts.model_name = \"LSTM_2\"\n",
    "opts.checkpoints_dir = \"./checkpoints_1/\" + opts.model_name\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "def read_batches(list_index, opts):\n",
    "    # discards the last chunks\n",
    "    shuffle(list_index)\n",
    "    merged_song = list(itertools.chain.from_iterable(list_index))\n",
    "    num_batch = math.ceil(1.0 * len(merged_song) / opts.seq_length)\n",
    "    for batch_index in range(0, num_batch):\n",
    "        if batch_index == num_batch - 1:\n",
    "            temp = merged_song[batch_index * opts.seq_length:]\n",
    "            if len(temp) <= 1:\n",
    "                inputs = temp\n",
    "                targets = []\n",
    "            else:\n",
    "                inputs = temp\n",
    "                targets = temp[1:]\n",
    "            inputs = np.pad(np.array(inputs), (0, opts.seq_length - len(inputs)), 'constant',\n",
    "                                constant_values=(0, 93))\n",
    "            targets = np.pad(np.array(targets), (0, opts.seq_length - len(targets)), 'constant',\n",
    "                                 constant_values=(0, 93))\n",
    "        else:\n",
    "            inputs = np.array(merged_song[batch_index * opts.seq_length:(batch_index + 1) * opts.seq_length])\n",
    "            targets = np.array(merged_song[batch_index * opts.seq_length + 1:(batch_index + 1) * opts.seq_length + 1])\n",
    "        inputs = np.expand_dims(inputs, axis=0)\n",
    "        targets = np.expand_dims(targets, axis=0)\n",
    "        input_tensors = torch.LongTensor(inputs)\n",
    "        target_tensors = torch.LongTensor(targets)\n",
    "        yield input_tensors, target_tensors\n",
    "'''\n",
    "def read_batches(list_index, opts):\n",
    "    #shuffle(list_index)\n",
    "    for itr in range(0, len(list_index)):\n",
    "        song = list_index[itr]\n",
    "        song_length = len(song)\n",
    "        num_batch = math.ceil(1.0 * song_length / opts.seq_length)\n",
    "        for batch_index in range(0, num_batch):\n",
    "            if batch_index == num_batch - 1:\n",
    "                temp = song[batch_index * opts.seq_length:]\n",
    "                if len(temp) <= 1:\n",
    "                    inputs = temp\n",
    "                    targets = []\n",
    "                else:\n",
    "                    inputs = temp\n",
    "                    targets = temp[1:]\n",
    "                inputs = np.pad(np.array(inputs), (0, opts.seq_length - len(inputs)), 'constant',\n",
    "                                constant_values=(0, 93))\n",
    "                targets = np.pad(np.array(targets), (0, opts.seq_length - len(targets)), 'constant',\n",
    "                                 constant_values=(0, 93))\n",
    "            else:\n",
    "                inputs = np.array(song[batch_index * opts.seq_length:(batch_index + 1) * opts.seq_length])\n",
    "                targets = np.array(song[batch_index * opts.seq_length + 1:(batch_index + 1) * opts.seq_length + 1])\n",
    "            inputs = np.expand_dims(inputs, axis=0)\n",
    "            targets = np.expand_dims(targets, axis=0) \n",
    "            input_tensors = torch.LongTensor(inputs)\n",
    "            target_tensors = torch.LongTensor(targets)\n",
    "            yield input_tensors, target_tensors\n",
    "\n",
    "\n",
    "    chunk = opts.batch_size*opts.seq_length\n",
    "\n",
    "    for i in range(0, batch_num): \n",
    "\n",
    "        if (i != batch_num-1):\n",
    "            start = i * chunk\n",
    "            end = start + chunk\n",
    "\n",
    "            #TODO check for chunking\n",
    "            inputs = all_characters[start:end]\n",
    "            targets = all_characters[start+1:end+1]\n",
    "\n",
    "            #TODO how you want to define batches?\n",
    "            input_tensors = torch.LongTensor(inputs).view(opts.batch_size, opts.seq_length)\n",
    "            output_tensors = torch.LongTensor(targets).view(opts.batch_size, opts.seq_length)\n",
    "\n",
    "        #TODO how do you want to tackle the last part\n",
    "        else:\n",
    "            start = i * chunk\n",
    "\n",
    "            inputs = all_characters[start:]\n",
    "            targets = np.concatenate((all_characters[start+1:], [idx_dict['end_token']]))\n",
    "\n",
    "\n",
    "            input_tensors = torch.LongTensor(inputs).view(1, len(inputs))\n",
    "            output_tensors = torch.LongTensor(targets).view(1, len(targets))\n",
    "        yield input_tensors, output_tensor\n",
    "'''\n",
    "\n",
    "\n",
    "# %%\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "\n",
    "        # self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first = True)\n",
    "        self.lstm = nn.LSTM(vocab_size, hidden_size, batch_first=True)\n",
    "\n",
    "        self.out = nn.Linear(hidden_size, vocab_size)\n",
    "        # self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        # encoded = self.embedding(inputs)  # batch_size x seq_len x hidden_size\n",
    "\n",
    "        # output, hidden = self.lstm(encoded, hidden)\n",
    "        output, hidden = self.lstm(inputs, hidden)\n",
    "        outputs = self.out(output)\n",
    "\n",
    "        return outputs, hidden\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters())\n",
    "        return (weight.new_zeros(1, bsz, 100),weight.new_zeros(1, bsz, 100))\n",
    "\n",
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)\n",
    "\n",
    "\n",
    "def training_model(train_characters, val_characters, vocab_size, idx_dict, model, opts, epochs=8):\n",
    "    model_optimizer = optim.Adam(model.parameters(), lr=opts.learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss().to(computing_device)\n",
    "\n",
    "    loss_log = open(os.path.join(opts.checkpoints_dir, 'loss_log.txt'), 'w')\n",
    "\n",
    "    best_val_loss = 1e6\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    loss_log.write('started training')\n",
    "    hidden = model.init_hidden(1)\n",
    "    for epoch in range(opts.n_epochs):\n",
    "\n",
    "        model_optimizer.param_groups[0]['lr'] *= opts.lr_decay\n",
    "\n",
    "        epoch_losses = []\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, epochs))\n",
    "\n",
    "        for i, (inputs, targets) in enumerate(read_batches(train_characters, opts)):\n",
    "\n",
    "            model_optimizer.zero_grad()\n",
    "            \n",
    "            inputs_embed = torch.FloatTensor(to_categorical(inputs, num_classes=vocab_size)).to(computing_device)\n",
    "            targets = targets.to(computing_device)\n",
    "            hidden = repackage_hidden(hidden)\n",
    "            outputs, hidden = model.forward(inputs_embed, hidden)\n",
    "            \n",
    "            loss = 0.0\n",
    "            \n",
    "            # TODO check\n",
    "            for j in range(targets.shape[1]):\n",
    "                loss += criterion(outputs[:, j, :], targets[:, j])\n",
    "\n",
    "            loss /= float(targets.shape[1])\n",
    "\n",
    "            # TODO check\n",
    "            loss.backward()\n",
    "\n",
    "            model_optimizer.step()\n",
    "\n",
    "            epoch_losses.append(loss.item())\n",
    "            \n",
    "            if 93 in inputs.cpu().detach().numpy()[0]:\n",
    "                hidden = model.init_hidden(1)\n",
    "\n",
    "            if (i % 100 == 0):\n",
    "                print(\"Batch: {}, Loss: {}\".format(i + 1, loss.item()))\n",
    "\n",
    "            if (i % 1000 == 0):\n",
    "\n",
    "                train_loss = np.mean(epoch_losses)\n",
    "                val_loss = evaluate(val_characters, model, idx_dict, criterion, opts)\n",
    "\n",
    "                if val_loss < best_val_loss:\n",
    "                    utils.store_checkpoints(model, opts)\n",
    "\n",
    "                generate_tune = generate_sequence('<start>', idx_dict, model,\n",
    "                                                  opts)  # TODO should we choose the best model here?\n",
    "                print(\n",
    "                    \"Epoch: {:3d}| Batch: {:3d} | Train loss: {:.3f} | Val loss: {:.3f} | Gen: {:20s}\".format(epoch + 1, i,\n",
    "                                                                                                              train_loss,\n",
    "                                                                                                              val_loss,\n",
    "                                                                                                              generate_tune))\n",
    "\n",
    "                loss_log.write('{} {} {}\\n'.format(epoch + 1, train_loss, val_loss))\n",
    "                loss_log.flush()\n",
    "\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "                utils.store_loss_plots(train_losses, val_losses, opts)\n",
    "\n",
    "                epoch_losses = []\n",
    "\n",
    "\n",
    "def evaluate(data, model, idx_dict, criterion, opts):\n",
    "    losses = []\n",
    "    hidden = model.init_hidden(1)\n",
    "\n",
    "    for i, (inputs, targets) in enumerate(read_batches(data, opts)):\n",
    "\n",
    "        inputs = torch.FloatTensor(to_categorical(inputs, num_classes=vocab_size)).to(computing_device)\n",
    "        targets = targets.to(computing_device)\n",
    "        hidden = repackage_hidden(hidden)\n",
    "        outputs, hidden = model.forward(inputs, hidden)\n",
    "\n",
    "        loss = 0.0\n",
    "\n",
    "        for j in range(targets.shape[1]):\n",
    "            loss += criterion(outputs[:, j, :], targets[:, j])\n",
    "\n",
    "        loss /= float(targets.shape[1])\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    mean_loss = np.mean(losses)\n",
    "\n",
    "    return mean_loss\n",
    "\n",
    "\n",
    "# %%\n",
    "def generate_sequence(start_string, idx_dict, model, opts):\n",
    "    char_to_index = idx_dict['char_to_index']\n",
    "    index_to_char = idx_dict['index_to_char']\n",
    "\n",
    "    # start_string = 'abc' #for a better hidden state, in our case should be stated with <start>\n",
    "    start_characters = np.asarray([char_to_index[c] for c in start_string], dtype=np.int32)\n",
    "\n",
    "    inputs = np.zeros((1, len(start_string)))\n",
    "\n",
    "    for i in range(0, len(start_string)):  # TODO limit here if want to start only with <\n",
    "        inputs[0, i] = start_characters[i]\n",
    "\n",
    "    inputs = torch.LongTensor(inputs)\n",
    "    hidden = None\n",
    "    inputs = torch.FloatTensor(to_categorical(inputs, num_classes=vocab_size)).to(computing_device)\n",
    "    outputs, hidden = model.forward(inputs, hidden)\n",
    "    output = outputs[:, -1:, ]\n",
    "\n",
    "    final_output_sequence = []\n",
    "\n",
    "    for i in range(opts.generate_seq_length):\n",
    "        probabilities = F.softmax(output.div(opts.temperature).squeeze(0).squeeze(0))\n",
    "\n",
    "        current_input = torch.multinomial(probabilities.data, 1)\n",
    "\n",
    "        final_output_sequence.append(current_input.data)\n",
    "\n",
    "        current_input = torch.cuda.FloatTensor(\n",
    "            to_categorical(current_input.cpu().detach().numpy(), num_classes=vocab_size)).unsqueeze(\n",
    "            0)  # .cpu().to(computing_device)\n",
    "\n",
    "        output, hidden = model.forward(current_input, hidden)\n",
    "\n",
    "    sampled_sequence = torch.cat(final_output_sequence, dim=0).cpu().detach().numpy()\n",
    "\n",
    "    geneated_seq = ''.join([index_to_char[i] for i in sampled_sequence])\n",
    "\n",
    "    return geneated_seq\n",
    "\n",
    "\n",
    "# %%\n",
    "# train_characters, vocab_size, idx_dict = load_data(opts.data_directory+opts.train_data_file)\n",
    "train_characters, vocab_size, idx_dict = load_data(opts.data_directory + opts.train_data_file)\n",
    "val_characters, _, _ = load_data(opts.data_directory + opts.val_data_file,idx_dict)\n",
    "model = RNN(vocab_size=vocab_size, hidden_size=opts.hidden_size)\n",
    "\n",
    "# Check if your system supports CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Setup GPU optimization if CUDA is supported\n",
    "if use_cuda:\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else:  # Otherwise, train on the CPU\n",
    "    computing_device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")\n",
    "\n",
    "model = model.to(computing_device)\n",
    "print(\"Model on CUDA?\", next(model.parameters()).is_cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    utils.create_dir_if_not_exists(opts.checkpoints_dir)\n",
    "    training_model(train_characters, val_characters, vocab_size, idx_dict, model, opts)\n",
    "\n",
    "    best_model = RNN(vocab_size=vocab_size, hidden_size=opts.hidden_size)\n",
    "    best_model = utils.restore_checkpoints(best_model, opts)\n",
    "    best_model = best_model.to(computing_device)\n",
    "    geneated_seq = generate_sequence('<start>', idx_dict, best_model, opts)\n",
    "    print(geneated_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_losses = np.load(\"train_losses.npy\")\n",
    "val_losses = np.load(\"val_losses.npy\")\n",
    "plt.figure()\n",
    "plt.plot(range(len(train_losses)), train_losses, label = 'Training Set Loss')\n",
    "plt.plot(range(len(val_losses)), val_losses, label = 'Validation Set Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('batch_size={}, lr={}, hidden_size={}'.format(opts.batch_size, opts.learning_rate, opts.hidden_size), fontsize=20)\n",
    "plt.xlabel('Epochs', fontsize=16)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_characters, _, _ = load_data('./Data/test.txt',idx_dict)\n",
    "model = RNN(vocab_size=vocab_size, hidden_size=opts.hidden_size).to(computing_device)\n",
    "model = utils.restore_checkpoints(model, './checkpoints_1/LSTM/best_model.pth')\n",
    "def read_batches(list_index, opts):\n",
    "    #shuffle(list_index)\n",
    "    merged_song = list(itertools.chain.from_iterable(list_index))\n",
    "    num_batch = math.ceil(1.0 * len(merged_song) / opts.seq_length)\n",
    "    for batch_index in range(0, num_batch):\n",
    "        if batch_index == num_batch - 1:\n",
    "            temp = merged_song[batch_index * opts.seq_length:]\n",
    "            if len(temp) <= 1:\n",
    "                inputs = temp\n",
    "                targets = []\n",
    "            else:\n",
    "                inputs = temp\n",
    "                targets = temp[1:]\n",
    "            inputs = np.pad(np.array(inputs), (0, opts.seq_length - len(inputs)), 'constant',\n",
    "                                constant_values=(0, 93))\n",
    "            targets = np.pad(np.array(targets), (0, opts.seq_length - len(targets)), 'constant',\n",
    "                                 constant_values=(0, 93))\n",
    "        else:\n",
    "            inputs = np.array(merged_song[batch_index * opts.seq_length:(batch_index + 1) * opts.seq_length])\n",
    "            targets = np.array(merged_song[batch_index * opts.seq_length + 1:(batch_index + 1) * opts.seq_length + 1])\n",
    "        inputs = np.expand_dims(inputs, axis=0)\n",
    "        targets = np.expand_dims(targets, axis=0)\n",
    "        input_tensors = torch.LongTensor(inputs)\n",
    "        target_tensors = torch.LongTensor(targets)\n",
    "        yield input_tensors, target_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def accuracy(out, labels):\n",
    "    outputs = np.argmax(out, axis=1)\n",
    "    #print(outputs.shape)\n",
    "    return np.sum(outputs[0]==labels[0]),labels.size\n",
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)\n",
    "    \n",
    "test_loss = []\n",
    "hidden = model.init_hidden(1)\n",
    "criterion = nn.CrossEntropyLoss().to(computing_device)\n",
    "#total_correct = 0.0\n",
    "#total_count = 0.0\n",
    "for i, (inputs, targets) in enumerate(read_batches(testing_characters, opts)):\n",
    "    inputs_embed = torch.FloatTensor(to_categorical(inputs, num_classes=vocab_size)).to(computing_device)\n",
    "    hidden = repackage_hidden(hidden)\n",
    "    outputs, hidden = model.forward(inputs_embed, hidden)\n",
    "    targets = targets.to(computing_device)\n",
    "    #outputs = torch.squeeze(outputs)\n",
    "    #targets = torch.squeeze(targets)\n",
    "    #outputs = F.softmax(outputs.div(1),dim=1)\n",
    "    #if 93 in inputs.cpu().detach().numpy()[0]:\n",
    "    #    hidden = model.init_hidden(1)\n",
    "    #targets_np = targets.cpu().detach().numpy()\n",
    "    #outputs_np = outputs.cpu().detach().numpy()\n",
    "    \n",
    "    loss = 0.0\n",
    "    #print(targets.shape)\n",
    "\n",
    "    for j in range(targets.shape[1]):\n",
    "        loss += criterion(outputs[:, j, :], targets[:, j])\n",
    "\n",
    "    loss /= float(targets.shape[1])\n",
    "    test_loss.append(loss.item())\n",
    "avg_loss = sum(test_loss)/len(test_loss)\n",
    "    #correct,count = accuracy(outputs_np,targets_np)\n",
    "    #print(outputs_np.shape)\n",
    "    #print(targets_np.shape)\n",
    "    #total_count +=count\n",
    "    #total_correct+=correct\n",
    "#print(total_correct)\n",
    "#print(total_count)\n",
    "#print(\"accuracy: \", total_correct/total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6298068626059425\n"
     ]
    }
   ],
   "source": [
    "print(avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
